<system>
  log_level "#{ENV['FLUENTD_LOGLEVEL'] || 'warn'}"
</system>

# The following label is to ignore Fluentd warning events. 
<label @FLUENT_LOG> 
  <match fluent.**> 
    @type null 
    @id ignore_fluent_logs 
  </match> 
</label>

# expose metrics in prometheus format
<source>
  @type prometheus
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
</source>
<source>
  @type prometheus_output_monitor
  interval 10
  <labels>
    hostname ${hostname}
  </labels>
</source>

<source>
  @type tail
  path /logs/access_logs.csv
  pos_file /logs/access_logs.csv.pos
  format csv
  keys id,url,method,name,surname,email,time
  time_key time
  tag access_logs
  @label @ENRICH_AND_TRANSFORMS
  refresh_interval 5
  rotate_wait 5
  read_from_head "true"
  encoding UTF-8
</source>

# count the number of incoming records per tag
<filter company.*>
  @type prometheus
  <metric>
    name fluentd_input_status_num_records_total
    type counter
    desc The total number of incoming records
    <labels>
      tag ${tag}
      hostname ${hostname}
    </labels>
  </metric>
</filter>

<label @ENRICH_AND_TRANSFORMS>
  <filter access_logs.**>
    @type record_transformer
    renew_record true
    enable_ruby true
    <record>
        value ${record}
        sent-time ${time.strftime('%Y-%m-%dT%H:%M:%S+07:00')}
        topic "#{ENV['KAFKA_TOPIC'] || 'access-logs-topic'}"
    </record>
  </filter>
  <match access_logs.**>
    @type relabel
    @label @INJESTION
  </match>
</label>

<label @INJESTION>
  <match **>
    @type kafka2
    brokers                       "#{ENV['KAFKA_BOOTSTRAP_SERVER'] || 'kafka:9092'}"
    use_event_time true
    topic_key                     topic
    default_topic                 "#{ENV['KAFKA_DEFAULT_TOPIC'] || 'default-logs-topic'}"
    headers                       producer:access-logs-logging
    discard_kafka_delivery_failed false
    <format>
      @type json
    </format>
    # See fluentd document for buffer related parameters: https://docs.fluentd.org/v/1.0/configuration/buffer-section
    # Buffer chunk key should be same with topic_key. If value is not found in the record, default_topic is used.
    <buffer topic>
      @type file
      path /logs/fluentd/buffer/access-logs
      flush_interval 60s      
    </buffer>
    # ruby-kafka producer options
    idempotent        true
    max_send_retries  1
    required_acks     -1 
    max_send_limit_bytes  10485760 # ( 10Mb like the message.max.bytes on kafka brokers ) Max byte size to send message to avoid MessageSizeTooLarge
    compression_codec gzip
  </match>
  <match **>
    @type copy
    <store>
      @type prometheus
      <metric>
        name fluentd_output_status_num_records_total
        type counter
        desc The total number of outgoing records
        <labels>
          tag ${tag}
          hostname ${hostname}
        </labels>
      </metric>
    </store>
  </match>
</label>

<match **>
  @type stdout
</match>
